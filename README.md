# Simple GenAI Chatbot using Streamlit and Ollama

This project is a **local Generative AI chatbot** built using **Streamlit** for the user interface
and **Ollama** for running open-source Large Language Models (LLMs) locally.
The chatbot supports conversational memory and runs entirely on the local machine
without using any external paid APIs.

---

<img width="845" height="664" alt="image" src="https://github.com/user-attachments/assets/9cd6bfd1-bd29-4aa0-af60-06108008fd4d" />


## üöÄ Features
- Interactive chat UI using Streamlit
- Runs open-source LLMs locally via Ollama
- Maintains chat history using Streamlit session state
- No OpenAI / paid API dependency
- Beginner-friendly and easy to extend

---

## üõ†Ô∏è Tech Stack
- **Python**
- **Streamlit**
- **Ollama**
- **LangChain**
- **Open-source LLMs** (Gemma / Phi / LLaMA)

---

## üì¶ Prerequisites
Make sure the following are installed:

- Python 3.9+
- Git
- Ollama (https://ollama.com)

---

## ‚öôÔ∏è Installation & Setup

### 1Ô∏è‚É£ Install Python dependencies
```bash
pip install streamlit langchain langchain-ollama
```Pull an LLM Model using Ollama
ollama pull gemma3:270m
```Run Sreamlit (command prompt)
python -m streamlit run main.py
```Open in a browser
http://localhost:8501


